{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n= 1000 Loop= 1\n",
      "n= 1000 Loop= 2\n",
      "n= 1000 Loop= 3\n",
      "n= 1000 Loop= 4\n",
      "n= 1000 Loop= 5\n",
      "n= 1000 Loop= 6\n",
      "n= 1000 Loop= 7\n",
      "n= 1000 Loop= 8\n",
      "n= 1000 Loop= 9\n",
      "n= 1000 Loop= 10\n",
      "Estimation for reg para and change point para:\n",
      "Theta:  [-0.99396505  2.05899697]\n",
      "eta:  2.0019996\n",
      "Estimation for Re and Sd of deep function:\n",
      "Re_g:  0.14533289\n",
      "Re_h:  0.17583993\n",
      "Re_total:  0.11999215\n",
      "SdRe_g:  0.011429506\n",
      "SdRe_h:  0.019241247\n",
      "SdRe_total:  0.01081113\n",
      "Inference for beta:\n",
      "Bias1: 0.006034949869911932\n",
      "Sse1:  0.0868563505213218\n",
      "Ese1:  0.08937937821334507\n",
      "Cp1:  1.0\n",
      "Inference for gamma:\n",
      "Bias2: 0.05899696667812826\n",
      "Sse2:  0.11887059885784668\n",
      "Ese2:  0.10493998647416211\n",
      "Cp2:  0.8\n",
      "Inference for zeta:\n",
      "Bias_eta: 0.0019996166\n",
      "Length_eta 0.00999999\n",
      "Sd_eta 0.0048000338\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as ndm\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from seed import set_seed\n",
    "from data_generator import generate_case_Deep\n",
    "from cpdplm_estimation import CPDPLM\n",
    "from LFDCP import LFDCP\n",
    "\n",
    "# data store\n",
    "F_test_deep = []; G_test_deep = []; Res_test_deep = []\n",
    "ThetaM = []; etaM = []\n",
    "Info1_deep = []; Info2_deep = []; Re_F_deep = []; Re_G_deep = []; Re_Res_deep = []\n",
    "corr = 0.5\n",
    "Theta = [-1,2]\n",
    "eta = 2\n",
    "\n",
    "# hyperparameters\n",
    "n_layer = 3\n",
    "n_node = 50\n",
    "n_epoch = 200\n",
    "patiences = 20\n",
    "n_lr = 1.2e-3\n",
    "\n",
    "# test data\n",
    "set_seed(14)\n",
    "test_data = generate_case_Deep(500,corr,Theta,eta)\n",
    "X_test = test_data['X']\n",
    "Z_test = test_data['Z']\n",
    "A_test = test_data['A']\n",
    "Y_test = test_data['Y']\n",
    "f_true = test_data['f_X']\n",
    "g_true = test_data['g_X']\n",
    "Res_true = test_data['f_X_C']\n",
    "\n",
    "# train & validation: 4:1\n",
    "# e.g. n = 1000\n",
    "n_tr = 800\n",
    "n_va = 200\n",
    "n = 1000\n",
    "# loop \n",
    "for b in range(10):   # corresponding to the length of eta\n",
    "    print('n=', n, 'Loop=', b+1 )\n",
    "    set_seed(114 + b)\n",
    "\n",
    "    # Generate data\n",
    "    train_data = generate_case_Deep(n_tr,corr,Theta,eta)\n",
    "    val_data = generate_case_Deep(n_va,corr,Theta,eta)\n",
    "\n",
    "    # Initial values\n",
    "    Theta0 = [0,1]  #initial theta\n",
    "    eta0 = np.mean(train_data['Z'])  # initial eta\n",
    "\n",
    "    \n",
    "    # Estimation\n",
    "    res = CPDPLM(train_data,val_data,test_data,Theta0, eta0,\\\n",
    "            n_layer, n_node, n_lr, n_epoch, patiences,show_val=False,maxloop=100,seq=0.01)\n",
    "      \n",
    "\n",
    "    # record the results\n",
    "    Theta_res = res['Theta'] # vector to add row by row\n",
    "    ThetaM.append(Theta_res)\n",
    "    eta_res = res['eta'] # change point\n",
    "    etaM.append(eta_res)\n",
    "  \n",
    "    \n",
    "    # test data to calculate Re and Sd_Re for g and h\n",
    "    f_test_res = res['f_test'] \n",
    "    F_test_deep.append(f_test_res) # vector to add row by row\n",
    "    g_test_res = res['g_test']\n",
    "    G_test_deep.append(g_test_res) # vector to add row by row\n",
    "    Res_test_res = res['f_C_test']\n",
    "    Res_test_deep.append(Res_test_res) # vector to add row by row\n",
    "    Re_F_deep.append(np.sqrt(np.mean((f_test_res-np.mean(f_test_res)-f_true)**2)/np.mean(f_true**2))) #Re loss of g(x)\n",
    "    Re_G_deep.append(np.sqrt(np.mean((g_test_res-np.mean(g_test_res)-g_true)**2)/np.mean(g_true**2)))\n",
    "    Re_Res_deep.append(np.sqrt(np.mean((Res_test_res-np.mean(Res_test_res)-Res_true)**2)/np.mean(Res_true**2)))\n",
    "\n",
    "    # Calculataion of the score and information\n",
    "    f_C_train = res['f_C_train']\n",
    "    f_C_val = res['f_C_val']\n",
    "    Z_train = train_data['Z']\n",
    "    Z_val = val_data['Z']\n",
    "    A1_train = train_data['A']\n",
    "    A1_val = val_data['A']\n",
    "    A2_train = train_data['A']*(Z_train>eta)\n",
    "    A2_val = val_data['A']*(Z_val>eta)\n",
    "    ## LFD for beta and gamma respectively, note as a1 and a2\n",
    "    a1 = LFDCP(A1_train, A1_val, train_data,val_data,Theta_res,eta_res,f_C_train, f_C_val,\\\n",
    "            n_layer=3,n_node=50,n_lr=2e-3,n_epoch=200,patiences=10,show_val = False)\n",
    "    a2 = LFDCP(A2_train, A2_val, train_data,val_data,Theta_res,eta_res,f_C_train, f_C_val,\\\n",
    "            n_layer=3,n_node=50,n_lr=2e-3,n_epoch=200,patiences=10,show_val = False)\n",
    "    Info = np.zeros((2,2))\n",
    "    Y_train = train_data['Y']\n",
    "    X_train = train_data['X']\n",
    "    A_train = train_data['A']\n",
    "    AC_train = np.vstack((A_train,A_train*(Z_train>eta)))\n",
    "    AC_train = AC_train.T\n",
    "    epsilon_train = Y_train - AC_train@Theta_res -f_C_train\n",
    "    Info[0,0] = np.mean(epsilon_train**2*(A1_train-a1)**2)\n",
    "    Info[1,1] = np.mean(epsilon_train**2*(A2_train-a2)**2)\n",
    "    Info[0,1] = np.mean(epsilon_train**2*(A1_train-a1)*(A2_train-a2))\n",
    "    Info[1,0] = Info[0,1]\n",
    "    Sigma = np.linalg.inv(Info)/n_tr\n",
    "    se1 = np.sqrt(Sigma[0,0])\n",
    "    Info1_deep.append(se1)\n",
    "    se2 = np.sqrt(Sigma[1,1])\n",
    "    Info2_deep.append(se2)\n",
    "#     time.sleep(1)\n",
    "\n",
    "\n",
    "#Error_g_dcp = np.mean(np.array(G_test_deep), axis=0) - g_true\n",
    "#Error_h_dcp = np.mean(np.array(H_test_deep), axis=0) - h_true\n",
    "#Error_Res_dcp = np.mean(np.array(Res_test_deep), axis=0) - Res_true\n",
    "Theta_dcp = np.mean(np.array(ThetaM),axis=0)\n",
    "eta_dcp = np.mean(np.array(etaM))\n",
    "Sd_F_deep = (np.sqrt(np.mean((Re_F_deep-np.mean(Re_F_deep))**2)))\n",
    "Sd_G_deep = (np.sqrt(np.mean((Re_G_deep-np.mean(Re_G_deep))**2)))\n",
    "Sd_Res_deep = (np.sqrt(np.mean((Re_Res_deep-np.mean(Re_Res_deep))**2)))\n",
    "ThetaM1 = np.array(ThetaM)[:,0]\n",
    "ThetaM2 = np.array(ThetaM)[:,1]\n",
    "Bias1_deep = (np.mean(np.array(ThetaM1))-Theta[0])\n",
    "Sse1_deep = (np.sqrt(np.mean((np.array(ThetaM1)-np.mean(np.array(ThetaM1)))**2)))\n",
    "Ese1_deep = (np.mean(np.array(Info1_deep)))\n",
    "Cp1_deep = (np.mean((np.array(ThetaM1)-1.96*np.array(Info1_deep)<=Theta[0])*\\\n",
    "                       (Theta[0]<=np.array(ThetaM1)+1.96*np.array(Info1_deep))))\n",
    "Bias2_deep = (np.mean(np.array(ThetaM2))-Theta[1])\n",
    "Sse2_deep = (np.sqrt(np.mean((np.array(ThetaM2)-np.mean(np.array(ThetaM2)))**2)))\n",
    "Ese2_deep = (np.mean(np.array(Info2_deep)))\n",
    "Cp2_deep = (np.mean((np.array(ThetaM2)-1.96*np.array(Info2_deep)<=Theta[1])*\\\n",
    "                       (Theta[1]<=np.array(ThetaM2)+1.96*np.array(Info2_deep))))\n",
    "Bias_eta = np.mean(np.array(etaM))-eta\n",
    "Sd_eta = np.mean(np.sqrt((np.array(etaM)-np.mean(np.array(etaM)))**2))\n",
    "etaMS = np.sort(np.array(etaM))\n",
    "Length_eta = etaMS[9]-etaMS[1]  #95% interval's length\n",
    "#print(Error_g_dcp)\n",
    "#print(Error_h_dcp)\n",
    "#print(Error_Res_dcp)\n",
    "print('Estimation for reg para and change point para: ')\n",
    "print('Theta: ', Theta_dcp)\n",
    "print('eta: ', eta_dcp)\n",
    "print('Estimation for Re and Sd of deep function: ')\n",
    "print('Re_g: ', np.mean(Re_F_deep))\n",
    "print('Re_h: ', np.mean(Re_G_deep))\n",
    "print('Re_total: ', np.mean(Re_Res_deep))\n",
    "print('SdRe_g: ', Sd_F_deep)\n",
    "print('SdRe_h: ', Sd_G_deep)\n",
    "print('SdRe_total: ', Sd_Res_deep)\n",
    "print('Inference for beta: ')\n",
    "print('Bias1: ', Bias1_deep)\n",
    "print('Sse1: ', Sse1_deep)\n",
    "print('Ese1: ', Ese1_deep)\n",
    "print('Cp1: ', Cp1_deep)\n",
    "print('Inference for gamma: ')\n",
    "print('Bias2: ', Bias2_deep)\n",
    "print('Sse2: ', Sse2_deep)\n",
    "print('Ese2: ', Ese2_deep)\n",
    "print('Cp2: ', Cp2_deep)\n",
    "print('Inference for eta: ')\n",
    "print('Bias_eta: ', Bias_eta)\n",
    "print('Length_eta: ', Length_eta)\n",
    "print('Sd_eta: ', Sd_eta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
